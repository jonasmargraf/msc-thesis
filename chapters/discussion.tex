% !TEX root = ../thesis.tex

\section{Discussion}
\label{sec:discussion}
In this final chapter, we discuss the reported results and offer some
interpretation and contextualization of them before moving on to a summary of
the work presented in this thesis, including a look at its strengths, weaknesses
and limitations. Finally, we suggest areas to explore in future work.

\smallskip

Section \ref{subsec:results_som_metrics} lays out the process of finding an
optimal set of parameters for a \gls{som} of the \textit{Drum Essentials} sample
library. Unsurprisingly, the longer the algorithm is trained, the better it
performs. Noticeable is the jump in quality for both quantization errors and
map emptiness when going from a training duration of $10^4$ to $10^5$. These
findings coincide with \citet{kohonen1990}, whose section on "Practical Hints
for the Application of the Algorithm" offers the following advice:

\begin{quotation}
“Typically we have used up to 100 000 steps in our simulations, but for
“fast learning”, e.g., in speech recognition, 10000 steps and even less may
sometimes be enough.”
\end{quotation}

A recommendation for users of \textit{SOM Browser} could be to find a general
combination of settings that works well for their audio files with $10^4$ steps
and then run the algorithm again for $10^5$ steps to further improve map
quality. Nonetheless it would be interesting to investigate this further and
see whether users actually perceive a noticeable difference when using
significantly longer training times.

\smallskip

Rather expectedly, a higher $\alpha_{initial}$ decreases map quantization errors
for our data set. This mirrors the theory behind the algorithm, according to
which more drastic node adjustment in the beginning of the training phase
creates the overall structure of the map, whereas at the end of training, when
$\alpha$ has decreased drastically, only minor local adjustments happen.
Starting with a lower $\alpha_{initial}$ would prohibit strong node adjustment
overall. Interestingly, the choice of $\alpha_{initial}$ does not seem to
improve vector node counts or map emptiness, which appear to hover around a
middle value in \ref{fig:som_alpha_effects}.

\smallskip

Our finding that larger starting values for the neighborhood function radius
actually produced worse results than using smaller starting radii contradicts
Kohonen's recommendations \citep{kohonen1990}, who states:

\begin{quotation}
“If the neighborhood is too small to start with, the map will not be ordered
globally. Instead various kinds of mosaic-like parcellations of the map are
seen”
\end{quotation}

Our subjective impression when exploring the map of drum sounds in
\textit{SOM Browser} does not immediately match this assertion. \gls{som} global
ordering could be further assessed by calculating maps for data containing group
labels and examining if data from the same group is mapped to the same area of
the \gls{som}.

\smallskip

When comparing the three different types of learning rate factors that were
implemented, the reciprocally decreasing function ("Inverse") was outperformed
by the two other methods. We believe the reason behind this to be that $\alpha$
drops off too strongly before the map has gained its global structure. BDH on
the other hand performs best out of all three methods, which most likely has to
be attributed to its ability to adapt the size of $\alpha$ locally. As to why
BDH delivered the smallest median quantization error with a choice of $m = 0$,
which effectively cancels out all adaptive local learning and results in a
constant $\alpha = \alpha_{initial}$, we are uncertain at this time.
The simulations presented in the original paper introducing the method obtain
best results for other values (see Figure 2 in \citep[p.18]{bauer1996}).
It should be noted however that the authors only examine one- and two-
dimensional input data.

\smallskip

With regard to \gls{fnp}, the extension to the original \gls{som} algorithm we
implemented, we consider it a practical usability improvement at the cost of
additional map distortion. Nevertheless, the enhancement of other aspects of the
produced map (most importantly, a lower map emptiness) justify its application.
Naturally, if more of the original map's nodes are populated to begin with, less
overall distortion will be added by applying \gls{fnp}.

\bigskip

While the conducted interviews were analyzed qualitatively, we did gather some
quantitative data through the usage of Likert scales. This was done to gauge
participants first reactions to \textit{SOM Browser} quickly and coarsely.
In Figure \ref{fig:results_ratings}, it can be seen at a glance that most
answers lie on the positive side of the scales.

\smallskip

With the median answer to question 2.2 about participants' satisfaction with
their current options for interacting with the presented sample library being
``somewhat satisfied'', and participants more in-depth responses showing some
frustrations, we infer that their current workflow can be seen as good enough,
but nothing more. Subjects are aware of its shortcomings and are interested in
new ways of working, which attests to the need for new tools such as what was
developed in this thesis. As a by-product of this interview series, a model for
the current practice of working with sample libraries could be established (see
Figure \ref{fig:results_current_workflow}). Particularly interesting is the
iterative interplay between participants mental representation of the sounds
they are looking for and contextual evaluation of their search results within
their production environment.

\smallskip



% Results interpretation
%
% Able to create application that can produce visual layout of samples with
% minimal to no input from user
%
% training length: another improvement after $10^5$ steps, should maybe look at
% if this is perceived noticeably better by users?
%
% Why are larger starting neighborhood radii worse than smaller ones? Contradicts
% Kohonen. K. mentions sharding / lack of global ordering, could be looked at
% (look at soms for data labelled with groups, e.g. subfolders)
%
% Why BDH minimum at m=0?
%
% Why BDH better than Linear? Local learning adaptability...
%
% FNP: adds distortion, but improves map emptiness and distribution of vectors to
% nodes, making it a practical usability improvement
% naturally, the better the original map is, the less distortion will be added
%
% Interview:
%
% established workflow appears to be "good enough", but nothing more
%
% a clear established workflow could be identified and summarized
%
% interesting is the iterative interplay of mental representation and contextual
% evaluation
%
% subjects are aware of limitations of their workflow, bias, etc
%
% SOM Browser: users first impressions were mostly positive, although they were
% not able to directly infer meaning to the presented map layout
% Some recognize areas of similarity, but the overall impression is that of a
% random organization
%
% While preference was with established workflow, the potential of the app was
% recognized
%
% Feature requests to improve usability: arrow keys, sample retriggering, larger
% font size
%
% Users also would like some more input, through color customization, feature
% filters, pre- / sub-categorization of files
%
%
%
% Reiterate aims / questions of work
%
%
%
% Most important results:
% - App itself
% - FNP: Algorithm extension for optimal utilization of allocated screen space
% - Interviews: Identification of existing workflow
% - Confirmed need for / interest in alternate interfaces and feedback was
% sufficiently positive to warrant further work in this direction
%
%
%
% Strengths of the work
% - Expert users that build their own MaxMSP performance systems got a new
%   addition to their toolbox by expanding mubu-catart with SOM
% - simple to use, cross-platform (untested) app that allows no-frills access to
%   a ML algorithm not found in any commercially available audio software
% - offers, quick, unsupervised visual layout of samples
% - can be used for completely unlabelled data
%
%
%
% Weaknesses of the work
% - reference missing inter-rater reliability,
% - potential bias in evaluation results
% - subjective coding
% - Incomprehensible Map Organization, perhaps due to question phrasing
%
%
% Limits of the work
% - no quantitative results
% - limited to one data set, only drum sounds
% - SOM Browser is not a tool for very large sample libraries, the used library
% pretty much presents the sensible limit of files
%
%
%
% What could be done better?
% - better feature model to optimize SOM as map of similarity
% - Interview: positioning of software as not finished
% - Interview: phrasing of question about map organization
%
%
%
% Outlook / potential future work
%
% - potential of the application
% - Map initialization using PCA
% - SOM batch algorithm
% - reimagining the software as a plug-in (M4L or as a VST using Juce etc.)
%
%
%
%
%
%
% node vector count: 4 corners have tons of samples
%
% 4 outliers are the 4 corners
%
% node vector count without FNP: clustering around edges
%
% Reference grounded theory?
%
% Special mention:
%
% Incomprehensible Map Organization
%
% Some recognize areas of similarity, but the overall impression is that of a
% random organization.
%
%
%
%
%
%
% better feature model for perceived similarity of sounds
%
% limit number of sounds that can be loaded (500?)
%
%
%
% \subsection{Outlook}
% \label{subsec:outlook}
