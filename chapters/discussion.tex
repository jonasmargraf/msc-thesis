% !TEX root = ../thesis.tex

\section{Discussion}
\label{sec:discussion}
In this final chapter, we discuss the reported results and offer some
interpretation and contextualization of them before moving on to a summary of
the work presented in this thesis, including a look at its strengths, weaknesses
and limitations. Finally, we suggest areas to explore in future work.

\subsection{Interpreting the Results}
\label{subsec:discussion_results_interpretation}

Section \ref{subsec:results_som_metrics} lays out the process of finding an
optimal set of parameters for a \gls{som} of the \textit{Drum Essentials} sample
library. Unsurprisingly, the longer the algorithm is trained, the better it
performs. Noticeable is the jump in quality for both quantization errors and
map emptiness when going from a training duration of $10^4$ to $10^5$. These
findings coincide with \citet{kohonen1990}, whose section on "Practical Hints
for the Application of the Algorithm" offers the following advice:

\begin{quotation}
“Typically we have used up to 100 000 steps in our simulations, but for
“fast learning”, e.g., in speech recognition, 10000 steps and even less may
sometimes be enough.”
\end{quotation}

A recommendation for users of \textit{SOM Browser} could be to find a general
combination of settings that works well for their audio files with $10^4$ steps
and then run the algorithm again for $10^5$ steps to further improve map
quality. Nonetheless it would be interesting to investigate this further and
see whether users actually perceive a noticeable difference when using
significantly longer training times.

\smallskip

Rather expectedly, a higher $\alpha_{initial}$ decreases map quantization errors
for our data set. This mirrors the theory behind the algorithm, according to
which more drastic node adjustment in the beginning of the training phase
creates the overall structure of the map, whereas at the end of training, when
$\alpha$ has decreased drastically, only minor local adjustments happen.
Starting with a lower $\alpha_{initial}$ would prohibit strong node adjustment
overall. Interestingly, the choice of $\alpha_{initial}$ does not seem to
improve vector node counts or map emptiness, which appear to hover around a
middle value in \ref{fig:som_alpha_effects}.

\smallskip

Our finding that larger starting values for the neighborhood function radius
actually produced worse results than using smaller starting radii contradicts
Kohonen's recommendations \citep{kohonen1990}, who states:

\begin{quotation}
“If the neighborhood is too small to start with, the map will not be ordered
globally. Instead various kinds of mosaic-like parcellations of the map are
seen”
\end{quotation}

Our subjective impression when exploring the map of drum sounds in
\textit{SOM Browser} does not immediately match this assertion. \gls{som} global
ordering could be further assessed by calculating maps for data containing group
labels and examining if data from the same group is mapped to the same area of
the \gls{som}.

\smallskip

When comparing the three different types of learning rate factors that were
implemented, the reciprocally decreasing function ("Inverse") was outperformed
by the two other methods. We believe the reason behind this to be that $\alpha$
drops off too strongly before the map has gained its global structure. BDH on
the other hand performs best out of all three methods, which most likely has to
be attributed to its ability to adapt the size of $\alpha$ locally. As to why
BDH delivered the smallest median quantization error with a choice of $m = 0$,
which effectively cancels out all adaptive local learning and results in a
constant $\alpha = \alpha_{initial}$, we are uncertain at this time.
The simulations presented in the original paper introducing the method obtain
best results for other values (see Figure 2 in \citep[p.18]{bauer1996}).
It should be noted however that the authors only examine one- and two-
dimensional input data.

\smallskip

With regard to \gls{fnp}, the extension to the original \gls{som} algorithm we
implemented, we consider it a practical usability improvement at the cost of
additional map distortion. Nevertheless, the enhancement of other aspects of the
produced map (most importantly, a lower map emptiness) justify its application.
Naturally, if more of the original map's nodes are populated to begin with, less
overall distortion will be added by applying \gls{fnp}.

\bigskip

While the conducted interviews were analyzed qualitatively, we did gather some
quantitative data through the usage of Likert scales. This was done to gauge
participants first reactions to \textit{SOM Browser} quickly and coarsely.
In Figure \ref{fig:results_ratings}, it can be seen at a glance that most
answers lie on the positive side of the scales.

\smallskip

With the median answer to question 2.2 about participants' satisfaction with
their current options for interacting with the presented sample library being
``somewhat satisfied'', and participants more in-depth responses showing some
frustrations, we infer that their current workflow can be seen as good enough,
but nothing more. Subjects are aware of its shortcomings and are interested in
new ways of working, which attests to the need for new tools such as what was
developed in this thesis. As a by-product of this interview series, a model for
the current practice of working with sample libraries could be established (see
Figure \ref{fig:results_current_workflow}). Particularly interesting is the
iterative interplay between participants mental representation of the sounds
they are looking for and contextual evaluation of their search results within
their production environment.

\smallskip

As for \textit{SOM Browser}, interview participants' first impressions were
mostly positive, yet also critical of several aspects of the software. Clearly,
much potential for improvement remains. Most importantly, subjects were not
able to comprehend the overall order of the map layout, which caused
frustration and some fairly critical responses. We believe there to be several
causes of this. It is certainly possible that the particular \gls{som} we
presented to subjects did not accurately serve as a similarity map of our
sample library, perhaps due to the previously discussed fact that we used a
small radius for the neighborhood function. This could've had the negative
effect on the global order of the map that is predicted by \citet{kohonen1990}
(see the quote above). At the same time, we suspect that a methodological flaw
in our question design could also have influenced participants' inability to
discern order within the map; we never suggested the map could have anything to
do with any kind of potential sonic similarity. Instead we asked ``What do you
think about the organization of sounds in this interface?'' and
``What do you think the axes represent?''. Some responses to the first question
did include ``there seem to be areas somehow'' and ``Okay, so these are the
percussion \dots'', perhaps indicating that some local similarities could be
identified, but not placed in a context concerning the entire map. But the
second question is effectively impossible to answer correctly; the axes of a
two-dimensional \gls{som} are in essence meta-features, or features of features.
This is not something that can be concluded without additional information.
When were aware of the impossible nature of the question when designing the
interview, but decided to ask it because we were interested in what possible
answers we would encounter. Instead, it would have perhaps been more beneficial
to position the map interface from the beginning as representing some sort of
similarity and then gauging whether participants can accept it and relate to it.

\smallskip

Participants clearly stated their preference for their established workflow.
This was to be expected, as our presented software is limited in scope and still
early in its development process. Additionally, interview participants were
professionals, who presumably have spent some time and effort to optimize their
workflow. Nevertheless, the participants recognized some potential in
\textit{SOM Browser} and stated a desire to explore incorporating it into their
workflow, under the condition that it could be integrated with their existing
production environments. Participants also mentioned numerous feature requests,
which could be incorporated into the software to improve usability, such as
support for Arrow key navigation, ways to filter by feature and some form of
additional categorization.

\subsection{Summary}
\label{subsec:discussion_summary}
In summarizing the present work, we can identify some strengths as well as
weaknesses that bear mentioning briefly. Listed in addition are limiting factors
of the work, before we move on to a discussion of potential future work and a
final conclusion.

\subsubsection{Strengths}
\label{subsubsec:discussion_strengths}
Our \gls{som} implementation offers a quick, unsupervised, visual layout of a
sound corpus. It can be used for completely unlabelled data and can therefore
be a benefit to audio experts and more casual music producers alike.
The addition of a \gls{som} implementation to \textit{CataRT} and \textit{MuBu
For Max} gives expert audio software users that build their own \textit{MaxMSP}
performance systems an addition to their existing toolbox. \textit{SOM Browser}
on the other hand is a simple to use, cross-plattform application that
allows no-frills contact with a \gls{ml} algorithm that can currently not be
found in commercial audio software.

\subsubsection{Weaknesses}
\label{subsubsec:discussion_weaknesses}
It stands to reason that the collection of audio features used in this work can
be improved upon, or should at least be reevaluated critically in order to
improve the quality of the produced maps. Interview participants struggled with
the presented map layout, which could be due to a lack of information, but also
due to insufficient quality of the \gls{som} they saw. \glspl{mfcc} could be
used to represent the spectral envelope of the sounds better. Additionally,
each sample's temporal envelope should be considered.

\smallskip

The qualitative analysis of the conducted interviews could also be improved upon
by using multiple independent researchers for the coding process. As it stands,
no inter-rater reliability exists, as the analysis was done by the author. This
also means that although care was taken to work diligently and objectively, the
potential for bias in the coding and the general interview evaluation
results is obvious.

\subsubsection{Limitations}
\label{subsubsec:discussion_limitations}
Although the \textit{Drum Essentials} data set used in this work can be
considered representative of a contemporary sample library, the work presented
here needs to be applied to other collections of sounds as well before it can
be considered more universally applicable. In conducting the interviews, we were
mainly interested in getting an overview of possible responses and reactions.
To this end, we chose a qualitative, semi-structured approach that prevents us
from presenting conclusive, quantitative results. Finally, a limitation of
\textit{SOM Browser} is that it is not a tool for very large sample libraries;
the library used by us, consisting of just over one thousand sound files,
presents essentially the sensible limit of files that can be displayed.

\subsubsection{Outlook}
\label{subsubsec:discussion_outlook}
As discussed earlier, \textit{SOM Browser} offers ample opportunity for future
work and improvements. A technical improvement could be the implementation of
the \textit{Batch Map}, which offers to potentially increase speed by an order
of magnitude \citep{web:kohonen2007}. Another welcome addition would be node
initialization using \gls{pca}, as can be done in the \gls{som} toolbox for
MATLAB \citep{vesanto2000}. Finally, a reimagining of the software in plug-in
format, either as a \textit{MaxForLive} device for Ableton Live or as a
\gls{vst} instrument, would be a more substantial undertaking that would satisfy
the desire of our interview participants for a more direct inclusion of
\textit{SOM Browser} functionality in their existing production environments.

\smallskip

For the \gls{som} algorithm as a whole and its utility for sound corpus
organization, an exploration of input dimension weightings for different
applications could be interesting. Perhaps the same set of features can be used
with different weightings depending on if the corpus contains percussive,
monophonic or polyphonic sounds. Additionally, an augmentation of the audio
feature input data with file metadata could also be considered. One can imagine
for example using a string distance function to compute file name similarity.


\subsubsection{Conclusion}
\label{subsubsec:discussion_conclusion}
The present thesis implements the Self-Organizing Map algorithm and applies it
to sound corpus organization. The implementation is embedded in two practical
applications. In \textit{MaxMSP}, it can be used to extend \textit{CataRT} and
the \textit{MuBu For Max} package, offering new possibilities to expert users.
In \textit{SOM Browser}, it is used for a fast, visual interface for
sample library exploration, offering an alternative to the established music
production workflow. In doing this, our software offers direct access to a
\gls{ml} algorithm that so far can not be found in any commercially available
audio software. We also extend the core algorithm with \gls{fnp}, a method that
allows an improved utilization of the screen space allocated for the \gls{som}
interface by reducing the areas of the map to which no sound is mapped.

\smallskip

After describing our approach to producing an optimized map for a chosen corpus
of drum sounds, we conduct a series of qualitative interviews with audio
professionals. Participants' responses allow us to identify a prevalent sample
library workflow, which we codify into a generalized model of the established
workflow. We confirm the need for and interest in alternate interfaces and
present participants with our developed software. Interview feedback was
sufficiently positive to warrant further work towards this end.


% Results interpretation
%
% Able to create application that can produce visual layout of samples with
% minimal to no input from user
%
% training length: another improvement after $10^5$ steps, should maybe look at
% if this is perceived noticeably better by users?
%
% Why are larger starting neighborhood radii worse than smaller ones? Contradicts
% Kohonen. K. mentions sharding / lack of global ordering, could be looked at
% (look at soms for data labelled with groups, e.g. subfolders)
%
% Why BDH minimum at m=0?
%
% Why BDH better than Linear? Local learning adaptability...
%
% FNP: adds distortion, but improves map emptiness and distribution of vectors to
% nodes, making it a practical usability improvement
% naturally, the better the original map is, the less distortion will be added
%
% Interview:
%
% established workflow appears to be "good enough", but nothing more
%
% a clear established workflow could be identified and summarized
%
% interesting is the iterative interplay of mental representation and contextual
% evaluation
%
% subjects are aware of limitations of their workflow, bias, etc
%
% SOM Browser: users first impressions were mostly positive, although they were
% not able to directly infer meaning to the presented map layout
% Some recognize areas of similarity, but the overall impression is that of a
% random organization
%
% While preference was with established workflow, the potential of the app was
% recognized
%
% Feature requests to improve usability: arrow keys, sample retriggering, larger
% font size
%
% Users also would like some more input, through color customization, feature
% filters, pre- / sub-categorization of files
%
%
%
% Reiterate aims / questions of work
%
%
%
% Most important results:
% - App itself
% - FNP: Algorithm extension for optimal utilization of allocated screen space
% - Interviews: Identification of existing workflow
% - Confirmed need for / interest in alternate interfaces and feedback was
% sufficiently positive to warrant further work in this direction
%
%
%
% Strengths of the work
% - Expert users that build their own MaxMSP performance systems got a new
%   addition to their toolbox by expanding mubu-catart with SOM
% - simple to use, cross-platform (untested) app that allows no-frills access to
%   a ML algorithm not found in any commercially available audio software
% - offers, quick, unsupervised visual layout of samples
% - can be used for completely unlabelled data
%
%
%
% Weaknesses of the work
% - reference missing inter-rater reliability,
% - potential bias in evaluation results
% - subjective coding
% - Incomprehensible Map Organization, perhaps due to question phrasing
%
%
% Limits of the work
% - no quantitative results
% - limited to one data set, only drum sounds
% - SOM Browser is not a tool for very large sample libraries, the used library
% pretty much presents the sensible limit of files
%
%
%
% What could be done better?
% - better feature model to optimize SOM as map of similarity
% - Interview: positioning of software as not finished
% - Interview: phrasing of question about map organization
%
%
%
% Outlook / potential future work
%
% - potential of the application
% - Map initialization using PCA
% - SOM batch algorithm
% - reimagining the software as a plug-in (M4L or as a VST using Juce etc.)
%
%
%
%
%
%
% node vector count: 4 corners have tons of samples
%
% 4 outliers are the 4 corners
%
% node vector count without FNP: clustering around edges
%
% Reference grounded theory?
%
% Special mention:
%
% Incomprehensible Map Organization
%
% Some recognize areas of similarity, but the overall impression is that of a
% random organization.
%
%
%
%
%
%
% better feature model for perceived similarity of sounds
%
% limit number of sounds that can be loaded (500?)
%
%
%
% \subsection{Outlook}
% \label{subsec:outlook}
